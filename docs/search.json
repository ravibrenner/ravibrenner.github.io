[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n⭐️⭐️⭐️⭐️⭐️ 5 Stars: Reviewing Online Reviews\n\n21 min\n\n\ngeneral\n\nstatistics\n\n\n\n\n\n\n\nFeb 19, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Desk Jobs and AI\n\n5 min\n\n\ngeneral\n\n\n\n\n\n\n\nFeb 9, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Vaccine Story\n\n7 min\n\n\ngeneral\n\n\n\n\n\n\n\nJan 28, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nPast Projects and Publications\n\n6 min\n\n\nprojects\n\n\n\n\n\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrad School Project Highlights\n\n5 min\n\n\nprojects\n\n\n\n\n\n\n\nJan 12, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout me and this blog\n\n3 min\n\n\ngeneral\n\n\n\n\n\n\n\nJan 5, 2026\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ravi Brenner",
    "section": "",
    "text": "Masters in Biostatistics student at Columbia University Mailman School of Public Health with a concentration in Public Health Data Science.\nI am a biostatistician and epidemiologist with experience using mathematical modeling, data analysis, and data visualization to support better health outcomes. I enjoy applying technical tools like R, Python, and SQL alongside strong writing and communication skills to tackle real-world challenges in public health. My interests include infectious disease epidemiology, health policy, vaccine-preventable diseases, HIV care, health communication, and looking for ways that data can inform public health action.\nThis website contains a bit about me and my work and educational experiences. You can also read a bit more about me in the blog section."
  },
  {
    "objectID": "posts/2026-01-22_past_projects_and_pubs/index.html",
    "href": "posts/2026-01-22_past_projects_and_pubs/index.html",
    "title": "Past Projects and Publications",
    "section": "",
    "text": "These are a few of the projects I have worked on in some of my past public health jobs. This is a sampling of final products, since there were plenty of other interesting projects that I worked on that didn’t turn into publications. More on those in another post in the future!\n\nHIV and COVID-19\nThis paper, Projecting the Clinical and Economic Impacts of Changes to HIV Care Among Adolescents and Young Adults in the United States: Lessons From the COVID-19 Pandemic was the first modeling paper that I got to work on from start to finish, under the supervision of Dr. Anne Neilan and a great team of collborators through the Adolescent Medicine Trials Network for HIV/AIDS Interventions (ATN). We wanted to understand what impact disruptions in HIV care due to COVID-19 would have on youth with HIV in the United States. We chose to focus specifically on the treatment side (rather than HIV prevention), and found that even short interruptions to HIV care may have negative long-term clinical implications (PDF is here).\nFor my part, I did literature reviews to understand the (early) state of research on the impact of COVID-19 on HIV care. I paid special attention to metrics like treatment adherence, loss to follow-up, and treatment failure among youth with HIV. I also helped to derive new youth-specific HIV care cost inputs for the model. Then we settled on a few strategies that we wanted to test, and I set up all the corresponding model runs and analyzed and visualized the data. Finally I helped with drafting and editing the paper, with much help from Dr. Neilan and the other co-authors.\nIn many ways, this was a speculative and exploratory paper. We were able to leverage some ATN data on youth with and without perinatal HIV to develop new model inputs unique to each population, which was a cool innovation. While not specifically what we modeled, I do think that in some ways we are now seeing the impact of these COVID care interruptions, nearly 6 years later. Data released by NYC this year show an uptick in new HIV diagnoses. That probably relates more to the prevention side of things than the treatment side, but its an unfortunate development nonetheless.\n\n\nCOVID-19 in Schools\nAnother set of analyses I was involved in related to COVID-19 contact tracing in Massachusetts schools. The first paper was Evaluation of “Test to Return” after COVID-19 Diagnosis in a Massachusetts Public School District and the second paper was Prevalence and Risk Factors for School-Associated Transmission of SARS-CoV-2. For both papers, we relied on data meticulously collected by school nurses and administrators in 2020 and 2021 on all cases and close contacts in their schools. I was not involved in designing the studies or collecting the data, but I was heavily involved in the data cleaning, analysis, and visualization for both studies.\nFor the test-to-return analysis, we wanted to know whether having students test before returning to school vs. waiting for a set number of days was better in terms of preventing infection and maximizing days spend in school. Ultimately we could not answer these questions with certainty, but we did find that a substantial proportion of students were still testing positive and may still be contagious 6 days after the onset of infection. Therefore if schools forgo testing to return to school, they should know that there may be some infectious students returning (PDF here).\nFor the school-associated transmission analysis, we were working with very complicated and messy data from a larger number of schools, so data cleaning was a substantial challenge. There was also a relatively small number of “events,” so the statistical analysis also proved an interesting challenge. The goal of the paper was simply to measure the secondary attack rate and factors associated with transmission in schools. Masking (prior to vaccine introduction) and full vaccination proved to be the strongest protectors against in-school transmission. The good news from this study was that secondary attack rates were relatively low, indicating that the preventative measures used were fairly effective and in-school learning could be resumed relatively safely (PDF here).\nDr. Nelson, Dr. Ciaranello, and other co-authors were involved in school COVID-19 policies in Massachusetts and nationally, and these studies were just part of the research base they were contributing to and drawing on. It was a challenging area of research, both from a data perspective and politically, and I hope that the work they did will prove useful the next time there is a disruptive pandemic.\n\n\nPolio in New York State\nI worked a lot on Polio while working at NYSDOH, but these were two papers that were actually published, led by the nonprofit modeling group Kid Risk. The papers were Modeling Poliovirus Transmission and Responses in New York State and Modeling undetected poliovirus circulation following the 2022 outbreak in the United States. My role in both of these was to provide a lot of the data on vaccination rates and the population at risk, and to help develop the modeling scenarios and visualizations.\nThe first paper provided an overview of the potential number of polio infections and paralytic cases under different mixing scenarios. We found that even when average IPV immunization rates are high, clusters of undervaccinated populations mean that imported polioviruses may circulate and pose a small but nonzero risk of causing paralysis in nonimmune individuals (PDF here).\nThe second paper was a bit more technical. We had been seeing wastewater samples positive for poliovirus, but no cases showing up with paralysis. Eventually we stopped seeing these detections, but it wasn’t clear that a negative sample meant that no one had polio. We wanted to know how confident we could be in no circulation based on the timing of the last positive wasterwater sample. We found that depending on the assumptions of population mixing and wastewater sampling quality, public health officials could assume 95% confidence of no ongoing circulation of the outbreak poliovirus within approximately 3–10 months since the last positive wastewater sample (PDF here.\nThese projects were a great experience for me, to see how modeling is used in a real outbreak setting. I also worked on some (unpublished) models internally for NYSDOH and in collaboration with CDC. The modeling was useful information to help us contextualize the risk: polio was probably not going to become endemic in New York, at least not in 2022-2023. Still, it did not solve the problem of how to increase on-time childhood vaccination (a topic for another day)."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume/CV",
    "section": "",
    "text": "Professional Experience\n\nData Analyst/Biostatistician\n\nMeyers Lab, Aaron Diamond AIDS Research Center, Columbia University, May 2025-Present\n\nConduct data cleaning and analysis of injectable HIV treatment using real world data from 8 clinics as part of the ALAI UP project\nCreate R Shiny dashboard to enhance monitoring, evaluation, and learning efforts\n\n\n\n\nProgram Research Specialist II/Data Analyst\n\nOffice of Science, New York State Department of Health, July 2022-July 2024\n\n\nAnalyzed millions of childhood immunization records using SAS, SQL, and R in support of state polio response and measles preparedness\nDesigned data strategy and training for program for community health workers to encourage uptake of childhood immunizations\nProduced ad-hoc data reports and literature reviews on emerging health topics shared with Health Commissioner\nDeveloped models of poliovirus and measles transmission to estimate outbreak size and potential using R and Excel, in collaboration with CDC\nCoordinated website strategy and advised on design of public dashboards, coordinating among 15 internal teams and 57 local health departments\nDeveloped and analyzed surveys of New Yorkers attitudes toward seasonal vaccines using SAS and presented findings to internal stakeholders which resulted in journal publication\n\n\n\n\nProject Coordinator\n\nMedical Practice Evaluation Center, Massachusetts General Hospital, August 2021-July 2022\n\n\nLed simulation modeling study of impact of COVID-19 on HIV care for youth with HIV resulting in first-author publication\nConducted additional modeling studies of life expectancy and optimal testing regimens for youth with HIV in the US and South Africa\nExecuted data cleaning and analysis of COVID-19 contact tracing data for thousands of students from Massachusetts public schools using R\nPresented results at internal meetings and conferences, using engaging and insightful visualizations\n\n\n\nResearch Assistant, August 2020-July 2021\n\nPerformed agent-based simulation modeling analyses to answer health policy questions related to youth with HIV\nDeveloped a new webtool using R Shiny and python to forecast global antiretroviral drug needs for children with HIV for the WHO\nAnalyzed data from cohort studies, clinical trials, and observational databases to inform model inputs\n\n\n\n\nUndergraduate Researcher\n\nFang-Yen Lab, University of Pennsylvania Bioengineering, , January 2019 – July 2020\n\nConducted independent research into the biomechanics of C. Elegans pharyngeal pumping\nPlanned and carried out various assays and experiments to understand worm feeding behavior\nCollected high speed footage of the microscopic worms using DIC microscopy\nAnalyzed video data and synthesized results into clear graphs and figures\nPresented results of research and contributed to writing of published journal article\n\n\n\n\nUnit Head\n\nCamp Yavneh, Northwood, NH, , June 2015 – August 2019\n\nManaged a staff of 11 counselors, including providing performance feedback and mediating disputes\nOrganized and planned leadership, educational, and recreational activities for 60 adolescent campers\nCoordinated day-to-day logistics, planned daily programs and events, and led field trips out of camp\nCorresponded with senior camp staff to address camper and counselor issues\n\n\n\n\n\nEducation\n\nColumbia Mailman School of Public Health, New York, NY\n\nExpected graduation: May, 2026\nMasters of Science in Biostatistics\nConcentration: Public Health Data Science\n\n\nUniversity of Pennsylvania, Philadelphia, PA, May 2020\n\nBachelor of Arts | Magna Cum Laude | Benjamin Franklin Scholar (80/2,500 students)\nMajor: Biological Physics (with Distinction) | Minor: Religious Studies\n\n\n\nSkills and interests\nTechnical skills: R/Rstudio, Python, SQL, SAS, MATLAB, Excel, Git/Github, Linear Algebra, Ordinary and Partial Differential Equations\nLanguage: Fluent in Hebrew\nInterests: Rock climbing, Guitar, Cooking, Running, Cycling"
  },
  {
    "objectID": "posts/2026-01-05_welcome_intro.html",
    "href": "posts/2026-01-05_welcome_intro.html",
    "title": "About me and this blog",
    "section": "",
    "text": "Welcome to the blog section of my website!\nMy name is Ravi, and I am a data-driven public health professional, with training as a biostatistician and experience with epidemiology and health policy. I have mainly worked on infectious disease in various capacities, both in academic research and in government public health.\nI started my professional career working on agent-based modeling projects at the Medical Practice Evaluation Center (MPEC) at Mass General Hospital. I primarily worked with Doctors Anne Neilan and Andrea Ciaranello on research related to youth with HIV in the US and South Africa. I also got the opportunity there to work on some primary data analysis projects related to COVID-19 in schools. After 2 years there, I began working in the Office of Science at the New York State Department of Health on emerging health science and outbreak response. I then took a break from working to learn some new skills in graduate school at the Columbia University Mailman School of Public Health. I am also currently working part time at the Meyers lab at the Aaron Diamond AIDS Research Center (ADARC), creating dashboards and doing data analysis to support clinics rolling out the next generation of injectable HIV treatment options.\nMore generally, I am interested in using data to inform public health action. I really enjoy the simulation modeling approach to this, since it is a fantastic way to understand the potential impact of different decisions. It can be complex and intellectually stimulating, and you can execute it when data is plentiful and when it is scarce. That said, I am also a big believer that sometimes the most important analysis needed is the simple one that can be executed quickly and disseminated effectively. Because of this, I also have a strong interest in communicating my analysis work to a broad audience. I enjoy creating different kinds of data visualizations and helping others to understand them, and am always interested in opportunities to teach to others.\nIn my non-work life I enjoy running, cycling, baking, and playing with our dog Maggie, a 2-year-old Australian Labradoodle (pictured).\nMy goal with this blog is to showcase some of my past work in more detail, discuss interests of mine in the public health field, and explore topics I am learning in more detail. I also hope it will provide an avenue for me to improve my writing and communication skills.\n\n\n\nMaggie with the sunsest behind her"
  },
  {
    "objectID": "posts/2026-02-09_desk_job_AI.html",
    "href": "posts/2026-02-09_desk_job_AI.html",
    "title": "On Desk Jobs and AI",
    "section": "",
    "text": "When I was a kid, I wanted to be an astronomer. Not an astronaut to be clear; I did not want to go to space. I wanted to be the one behind the telescope, exploring the universe from the earth.\nAs I grew my interests changed. In college I thought maybe I would become a teacher, or work in experiential education of some kind. Its still something I think about pursuing one day, if the circumstances were right. My first paying job was as a camp counselor and unit head, which I loved.\nLater in college, convinced I had to get a “real” job, I worked in a research lab, staring down a microscope at C. Elegans, microscopic worms. I enjoyed this job a lot too. It was much more solitary, but I would put in some headphones and tend to my worms, prepare my slides for the microscope, and spend hours recording their movements. I decided I wanted to pursue a career that was closer to human health and wellbeing, rather than being purely research-based. But I liked all the activities that came with working in a lab.\n\n\n\nA plate of my C. Elegans worms\n\n\nWhat I did not want to do, what I dreaded and avoided, was work behind a desk in an office, staring at a computer all day. It sounded boring and monotonous, and what could you accomplish from behind a desk? I knew lots of people had such jobs, but I also knew there were many other options. When I graduated college I applied to work at a science-based summer camp, at an environmental education center, and in science labs. But the job that I landed was as a Research Assistant at MGH, working (from home initially) behind a computer. Editing excel sheets and slide decks all day. It wasn’t what I had in mind.\nBut it turns out I liked it, and I was good at it.\nMy first week at my current role, one of my new co-workers commented that they “couldn’t believe you just sit their quietly and work for so long,” but that’s exactly what I do. The time flies by, and I can get a lot done just sitting at my computer. There are articles to read, code to be written, papers to write, files to be organized. And I have found across all of the desk jobs that I have had that the work can be very rewarding. Its not the immediate reward of being a camp counselor and getting to see kids enjoy the activities you put together. But other public health professionals, doctors, clinic staff, and patients have benefited from my work behind a desk.\n\n\n\nThe view of NYC from the ADARC office\n\n\nI am a fairly agreeable person. I tend to like, or at least tolerate, a lot of circumstances. Which is to say I’m sure I would enjoy other work settings too, maybe even more so then working at a desk. I still think about teaching or working outdoors somehow, or making my baking hobby into a job. But for now, I have lucked into a career path where I can thrive.\n\nAI and me\nSo far, my experience with AI tools is that they can usually do things faster, if slightly worse, than I can do on my own. This can be empowering in many ways, because anyone can go from having nothing to having something in just a few seconds. From what I have read, AI agents are even a step better than this, and experienced software engineers are apparently writing little of their own code now. In some ways this is great.\nAn obvious concern is that the adoption of AI will automate away many workers like me. My work is largely done at a computer, so a super advanced computer could probably do it.\nOn one level, I still think I have a lot to add. Generative AI models often wrong, but you need to know enough to know when they are wrong. I frequently work with patient data, which can’t simply be put into LLMs without substantial safeguards. And much of the work I do is very nuanced and complex, and even if an AI model could do a version of it, getting everything exactly right is hard. Certainly I am a biased observer about this, but I think I’m still better than the machines.\nI use AI when I can, for helping with code, speeding up the question-answer debugging process, and helping me search for and learn new tools and techniques. I think all of that is useful and I’ll continue to use it in my work.\nOn another level though, the rise of AI is a bit of a personal bummer. I find I can usually do things better than an AI model, just more slowly. Investing hours, days, or months at learning a new skill or technique is rarely worthwhile from an efficiency point of view, so AI has a use in those situations. But I enjoy learning new things, puzzling through difficult tasks, and plugging away behind my computer. It’s great if AI automates some of that and frees me up to do the more mentally stimulating things, but if my job is automated away I’ll be left with nothing. That’s a sad future to contemplate."
  },
  {
    "objectID": "posts/2026-01-26_my_antivax_story/index.html",
    "href": "posts/2026-01-26_my_antivax_story/index.html",
    "title": "My Vaccine Story",
    "section": "",
    "text": "Fear of needles\nWhen I was 17, I drove myself to the pediatrician for the first time, without my parents. After most of the physical exam had concluded, my doctor asked me if I wanted to get the relatively new meningococcal B vaccine. The CDC had recently recommended MenB vaccine for “individual clinical decision making.” I was at the right age to receive the vaccine, and there was a low but meaningful risk of the disease on college campuses at the time.\nI was and remain terrified of needles (like over half of adults). My pediatrician knew this, since I had nearly passed out in his office a few years prior. The vaccine was new, and based on the relatively weak recommendation from the CDC ACIP, he told me: “You can probably skip this one.” With no parents there to tell me otherwise, that’s exactly what I did.\nI diligently, if nervously, got all my flu shots in college. I even took myself to get a Tdap booster, after which I nearly fainted and had to lie down with a juice box at age 22. I jumped at the opportunity to get the single-dose J&J COVID-19 vaccine in 2021 because it meant I only had to get a single dose. I have never even attempted to give blood, since the couple of times I have had blood drawn, it has been a challenge to remain conscious. I try my best to put on a brave face, but even the sight of a needle on TV makes me lightheaded.\n\n\n\nMy roommate and I getting our COVID-19 booster doses in late 2021\n\n\nI completely understand the fear some people have of vaccines. Even if you can put up with the needles, which I can, its still unpleasant. Your arm hurts, you might feel off for a few days afterward. The weight-loss-drugmakers know this and are creating oral options. There are some oral and nasal vaccine options, but they haven’t been developed for all diseases and the performance of the vaccine can vary a bit. So for many people, they have to overcome a real fear to get vaccinated.\nThere’s a social component too. In college, there was a flu vaccine “fair” in the main student center, which all my friend attended and where some of my friends volunteered. There was a lot of (positive) peer pressure to get vaccinated.\n\n\n\nAn Outbreak in New York\nIn July 2022, I started a new job in the Office of Science at the New York State Department of Health. Just a few days in (I was still getting my computer set up), my boss called. “We don’t know for sure yet,” he said, “but we think there is a person hospitalized with polio down state.” “Polio?” I asked, puzzled. I genuinely thought we had eliminated polio from the US. Turns out that we had, and that this case was likely imported from abroad by a traveler to another country.\nThere was no team set up to deal with a polio outbreak. So several teams across NYSDOH and CDC, including our own, got to work. My boss had a specific ask for me. Could we estimate how many people were at risk of getting polio, and how many cases might we see in New York?\nThe case and subsequent outbreak occurred in the state’s significant Haredi Jewish community. While I am not Haredi myself, I grew up in the Modern Orthodox Jewish community in upstate New York. I knew plenty of religious Jews, including some who did not generally vaccinate themselves or their children. So when my boss asked how many people were at risk of getting polio, it was a question about understanding the dynamics of this community in particular.\nThis was not the first vaccine-preventable disease outbreak in this particular community (there had been mumps and measles within recent memory). Haredi Jews tend to have large families, so there were always young children vulnerable to these diseases being born. Each new outbreak led to a similar pattern: some parents would have their children immunized, and other children would get sick and survive with immunity, only for a new disease to show up a few years later for the cycle to repeat.\nFollowing the 2018-2019 measles outbreak, the state eliminated non-medical exemptions to most vaccines for school entry. This worked, to a point. Some schools never complied, there have been occasional episodes of fraud, and some parents just delayed vaccination until school entry, leaving their children under 5 vulnerable. There was a lot of anti-vaccine sentiment in the community.\n\n\n\nMeasles vaccination rates in New York State\n\n\nHonestly, I understood where they were coming from. There is frequent scrutiny by the state government and the media over how Haredi Jews run their schools. So when state officials came to them begging, once again, to bring their children in for vaccines, many parents were skeptical. Many parents were young and themselves not vaccinated. It wasn’t the social norm to get vaccinated, and it certainly wasn’t the norm to trust the government, or worse, faraway doctors whose vaccines did not appear to prevent repeated outbreaks from occurring.\nWe worked hard to come up with solutions, to rebuild trust so that people would choose to vaccinate their children. But ultimately it was a problem that took years to create, and one that will take years to solve.\n\n\n\nWhat to do?\nFast forward to 2026, and obviously we have not solved this problem. Distrust in vaccines, and in public health in general, is higher than ever. HHS, led by RFK Jr., has removed some vaccine recommendations, and his handpicked leader of ACIP has questioned the need for polio and measles vaccines entirely.\nVaccine acceptance can be thought of as a spectrum or pyramid. At the bottom are those who receive all recommended doses. Then there are smaller segments of people that are hesitant or selective. They may get some vaccines, but maybe not all on the recommended schedule. At the top, the smallest group of people, are the decliners who receive no vaccines under any circumstances.\n\n\n\nThe vaccine pyramid\n\n\nRecently Dr. Paul Offit called RFK Jr. a “vaccine cynic” which I agree is a much better term for him than “skeptic.” Skepticism is normal, and a healthy part of the scientific process. We should be skeptical of new vaccines and medical treatments, and carefully scrutinize the evidence when deciding whether to use them. That is just what scientists, doctors, and regular people all over the country have done for decades. I think that is what most people do who are hesitant or selective about vaccines. RFK Jr. and his supporters in the government are not like that. They contort evidence to fit their preconceived conclusions, a complete inversion of the scientific method.\nI have a lot of empathy for those unsure about vaccines. Needles are scary. We don’t always feel we can trust what scientists and government officials are saying. I completely understand how someone might hear that vaccines don’t work or are unsafe and simply decide that its not worth it for them that day. I hope they can be persuaded otherwise one day.\nI have a harder time understanding the vaccine cynic position. For me, its hard to understand why RFK Jr. is so opposed to vaccines, and why so many people find that view appealing. For a public health communications class, I recently read an article about “identity protection cognition”: basically the idea that people’s beliefs are downstream of their group identity. I think that is at least part of the answer, and something that effects us all. The author, Dan Kahan, also points out that those with the most scientific knowledge are often the most polarized. As someone with a good amount of scientific knowledge myself, I don’t want to fall into that trap. One fear I have about the public health field today is that we risk becoming so (reasonably!) angry by attacks on science that we risk losing our empathy for those who don’t share our views. Empathy which is non-negotiable in public health.\nFor my own part, I am interested in understanding why people choose not to vaccinate and how they can be persuaded to do so. I am far from an expert on this (and I’m sure this post violates some “best practices” in that area), but I hope to lead with empathy and transparency in the work that I do."
  },
  {
    "objectID": "posts/2026-01-12_grad_school_projects/index.html",
    "href": "posts/2026-01-12_grad_school_projects/index.html",
    "title": "Grad School Project Highlights",
    "section": "",
    "text": "These are 3 projects I have completed for classes as part of my masters degree. There are links to the final presentation, poster, and reports I wrote for each of these, as well as a github repo with the accompanying code.\n\nInfectious disease transmission trees\nThis was the final project for my network science class, taught by Dr. Sen Pei. It was heavilty inspired by this paper, and the data are from here. I worked on it with a partner in the class, and the final presentation can be found here. There is also a github repo containing some of the work I did on this project.\n\n\n\nA sample outbreak tree showing different types of nodes\n\n\nWe chose to look at infectious disease transmission trees because they provide an interesting was of understanding outbreak dynamics. You can calculate the basic reproductive number \\(R_0\\) from a transmission tree by calculating the average out-degree of a node in the network (the out-degree is just the number of arrows pointing out of the node). However once an outbreak is completed, this will be &lt;1, so you have to exclude some share of the nodes to calculate the “true” \\(R_0\\). It’s a good reminder that basic reproductive numbers are probabilistic and influenced by the specific dynamics of an outbreak and the qualities of the disease. For example, the number of clusters influences the average \\(R_0\\), and identifies superspreaders at the same time, but these two things may have a somewhat inverse relationship. Diseases that spread quickly (like measles) may actually have fewer “superspreaders” in a strict sense, because basically everyone is transmitting at a high rate. We also categorized the different diseases based on the number of nodes (the size of the outbreak) and the number of clusters (superspreaders) and some interesting patterns emerged.\n\n\nBike Lanes and Bike Collisions in New York City\nThis was the final project for my public health GIS class, taught by Dr. Joel Capellan. The final poster I produced with my findings is available as a powerpoint file in this github repo with all my other work. This subject was personally interesting for me because I bike for exercise and occasionally for commuting in New York City. I had wanted to undertake an analysis of bike safety in New York but felt daunted by the sheer size of the data shared by NYC on their Open Data portal. The vehicle collision data is very large, and wrangling that data was a challenge. On top of that, for this analysis I was dealing with points (where crashes occurred), line segments (where bike lanes were present), and polygons (where different community districts are located). So connecting all those geometries took some thought and decision making.\n\n\n\nOne map I produced for this project\n\n\nThis project also illuminated for me how challenging this type of research can be. The data NYC provides is very good and detailed, but still not enough to make any definitive conclusions about safety, because traffic volumes on each line segments are unknown. There are some traffic volumes provided by NYC at specific locations, but it’s hard to extrapolate from that to the whole city. Still, it was a fun data visualization project, and our professor kindly printed out our posters in full size for our presentation day.\n\n\nSimulation of Bias-Variance Tradeoff with Tree-Based Models\nThis last project is a more technical and theoretical machine learning project, for the course “Topics in Statistical Learning & Data Mining” taught by Dr. Min Qian. I still think it was very interesting to work on, and even those who are not data scientists, statisticians, or machine learning engineers can benefit from learning about this. The final report I produced is available as a PDF in this github repo for the project.\nVery briefly, the project attempts to explore and understand the bias-variance tradeoff in machine learning. The basic idea is that when you create a model to try to predict some outcome, the goal is to minimize some kind of error. You can show with some math that the error can be broken down into 2 components, called the bias and the variance. The bias tells you how far your predictions are from the truth, and the variance tells you how varied your predictions are. It turns out that these 2 things are somewhat in conflict, such that decreasing the bias means increasing the variance, and vice versa.\n\n\n\nPhoto from wikipedia\n\n\nIt’s the sort of thing that is often glossed over quickly at the beginning of a data science class, but its very important to understand, especially as AI becomes more ubiquitous. Today’s generative large language models are far more complicated than the models I explored in this paper, but they too suffer from the bias-variance tradeoff. This project was a cool way to explore how I could bridge theoretical constructs and actual data analysis, and I came away feeling like I understood this concept in a way I really hadn’t before."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Brenner IR, Flanagan CF, Penazzato M, Webb KA, Horsfall SB, Hyle EP, Abrams E, Bacha J, Neilan AM, Collins IJ, Desmonde S, Crichton S, Davies MA, Freedberg KA, Ciaranello AL. Cost-effectiveness of viral load testing for transitioning antiretroviral therapy-experienced children to dolutegravir in South Africa: a modelling analysis. The Lancet Global Health. 2024;12(12):e2068-e2079. doi:10.1016/S2214-109X(24)00381-4\nKalkowska DA, Badizadegan K, Routh JA, Burns CC, Rosenberg ES, Brenner IR, Zucker JR, Langdon-Embry M, Thompson KM. Modeling undetected poliovirus circulation following the 2022 outbreak in the United States. Expert Review of Vaccines. 2024;23(1):186-195. doi:10.1080/14760584.2023.2299401.\nNeilan AM, Ufio OL, Brenner IR, Flanagan CF, Shebl FM, Hyle EP, Freedberg KA, Ciaranello AL, Patel K. Projected Life Expectancy for Adolescents With HIV in the US. JAMA Health Forum. 2024;5(5):e240816. doi:10.1001/jamahealthforum.2024.0816.\nMitchell EC, Nguyen T, Boulais M, Brenner IR, Dorabawila V, Hoen R, Li Y, Cavazos M, Levine B, Anderson BJ, Battles H, Brissette I, Backenson B, Lutterloh E, Bauer UE, Rosenberg ES. Home testing for SARS-CoV-2 and impact on surveillance in New York State. Annals of Epidemiology. Published online November 22, 2023. doi:10.1016/j.annepidem.2023.11.009.\nBrenner IR, Simpson KN, Flanagan CF, Dark T, Dooley M, Agwu AL, Koay WLA, Freedberg KA, Ciaranello AL, Neilan AM. Projecting the clinical and economic impacts of changes to HIV care among adolescents and young adults in the US: lessons from the COVID-19 pandemic. J Pediatric Infect Dis Soc. Published online November 14, 2023:piad102. doi:10.1093/jpids/piad102.\nThompson KM, Kalkowska DA, Routh JA, Brenner IR, Rosenberg ES, Zucker JR, Langdon-Embry M, Sugerman DE, Burns CC, Badizadegan K. Modeling poliovirus transmission and responses in New York State. J Infect Dis. 2023 Aug 19:jiad355. doi: 10.1093/infdis/jiad355. Epub ahead of print. PMID: 37596838.\nNelson SB, Dugdale CM, Brenner IR, Crawford A, Bilinski A, Cosar D, Pollock NR, Ciaranello A. Prevalence and Risk Factors for School-Associated Transmission of SARS-CoV-2. JAMA Health Forum. 2023 Aug 4;4(8):e232310. doi: 10.1001/jamahealthforum.2023.2310. PMID: 37540523; PMCID: PMC10403780.\nNelson SB, Brenner IR, Homan E, Lee SB, Bongiorno C, Pollock NR, Ciaranello A. Evaluation of “Test to Return” after COVID-19 Diagnosis in a Massachusetts Public School District. J Sch Health. 2023 Jun 4. doi: 10.1111/josh.13357. Epub ahead of print. PMID: 37272202.\nBrenner IR, Raizen DM, Fang-Yen C. Pharyngeal timing and particle transport defects in Caenorhabditis elegans feeding mutants. J Neurophysiol. 2022 Aug 1;128(2):302-309. doi: 10.1152/jn.00444.2021. Epub 2022 Jun 22. PMID: 35730757."
  },
  {
    "objectID": "posts/2026-02-16_reviews_of_reviews.html",
    "href": "posts/2026-02-16_reviews_of_reviews.html",
    "title": "⭐️⭐️⭐️⭐️⭐️ 5 Stars: Reviewing Online Reviews",
    "section": "",
    "text": "“Mama’s Too” is an amazing pizza restaurant, not far from where I live in New York City. It was recently listed as one of the best slices in the world, and I seriously recommend trying to go if you are in New York. The cacio e pepe and poached pear slices are out of this world.\nVillage Square Pizza is an NYC chain, that makes very good pizza, but nothing special for NYC. They have a location closer to my apartment, so I go there a bit more frequently.\nOn Google maps, Mama’s Too has a 4.2 average rating with 2,650 reviews, and Village Square has a 4.6 average rating, with 129 reviews. The distributions look like this:\n\n\n\n\n\n\n\n\n\nWhich restaurant is better? You already know my opinion. But what if you’re going to a new place, and you don’t know anything about either restaurant except for the Google reviews? How can you make a decision? In practice, I find this is a big issue for me when I’m traveling to a new place. Trying to figure out where to eat or which hotel or Airbnb to stay at is a big challenge. In this post I’ll discuss a variety of factors that might influence your choice when looking at reviews.\n\nSocial factors\nObviously, a lot goes into reviews like this. Unlike a survey, reviews are inherently very biased. Here are a few things that go into that bias:\n\nSelf selecting reviewers. The people who choose to review a restaurant are not a random sample. Personally, I have only left reviews when its either highly encouraged by the platform (like Airbnb) or if the owner specifically asks for my review (like at my dentists office). But many people have a hobby of reviewing places, and there are even special platforms (like Beli for restaurants) that cater to people who like reviewing things as an activity in itself. On the other end of the spectrum, some people only leave a review if their experience is negative and they are trying to warn people or get compensated. Speaking of…\nPolarized reviews. As you can see from the distribution for Village Square above, people are like to leave 5 stars as a baseline (like with Uber/Lyft rides), or to leave 1 star if something bad happened, like slow or rude service at a restaurant with otherwise good food. This leads to polarized reviews, where there are few 2-4 star ratings that may be more “objective.”\nDifferent platforms. Reviews and reviewers on Google may vary a lot compared to Yelp or other sites. In fact, the average review on Google may be around 4.2 compared to 3.5 on Yelp. This can also vary widely by industry and city. For example I have noticed that the average ratings of restaurants at airports and at gas stations are always very low. Those places just don’t get good reviews much, so an “above average” airport restaurant may have a lower review than a regular restaurant. I also find this a challenge when comparing hotels, which may have reviews on multiple different platforms (e.g. Expedia, hotels.com, booking.com, kayak, Google, etc.) that can be hard to compare.\nEarly vs. late adopters. The first customers as a restaurant may be friends or enthusiasts more likely to give high reviews.\nViral trends. Related, if a restaurant gains popularity for being viral, things can get weird. Tourists coming to get the viral food may be extra lenient, while others may be extra critical in response to the hype. Furthermore this population differs from “in the know” locals, who may know good spots that receive less attention.\nDiffering preferences. Everyone looks for different things in writing and reading reviews. Some people may give qualified reviews that are influenced by their own perspectives. A common one I see living in New York is people giving a negative review, and writing that a place is “good but too expensive.” Cleanliness, wait times, uniqueness, and differing palates can all change how you interpret reviews.\n\n\n\nSurvivorship bias\nTurning to the statistical aspects of reviews, a subtle bias that can occur is survivorship bias. Survivorship bias occurs when you fail to take into account the process by which your sample came to be, overlooking the selection process that may have occurred (see Wikipedia for more).\nA classic example comes from military history. During World War II, planes would return to base full of bullet holes. How could the allies reinforce their planes so that more were able to return to base? One might naively think you should reinforce the areas full of bullet holes. However the correct approach would be to reinforce the areas that were not hit. Why? The planes that were hit in those areas never returned to base at all. Only considering the survivors can bias our assessment.\nIn the case of restaurants, something similar occurs. Bad restaurants just close. Enough bad reviews leads to bad business. Airport restaurants and gas stations are impervious to bad reviews, so they can stay open. But in a place like New York City, with thousands of restaurants and hundreds for each cuisine, the competition leads to a survival of the fittest.\nThis leads to two interesting quirks.\nFirst, it means that the high average rating of Google restaurant reviews may not be an anomaly, since the bad restaurants are closed. You can see this by simulating the process of how the data is generated. If we simulate 2500 restaurants with random reviews and random numbers of ratings, we get a big cloud. Here, number of ratings corresponds to how long a restaurant has been open. We can imagine a cutoff line in red, where below that line, restaurants close. Note that there is no relationship here between number of reviews and average rating.\n\n\n\n\n\n\n\n\n\nNow if we remove those points below the line, we can see that there is a relationship between number of reviews and average review, shown by the sloped linear regression line in blue.\n\n\n\n\n\n\n\n\n\nAlso, the average review score went up:\n\n\n\n\n\nAverage rating\nAverage survivor rating\n\n\n\n\n3.006728\n3.385118\n\n\n\n\n\nSecond, it means that, in New York at least, even “average” pizza places must be pretty good just to survive and stay open. So you have a pretty good chance of having a good experience even if the reviews aren’t stellar. The flip side of this is that if a place has really bad reviews its probably best to avoid altogether.\n\n\nA strange scale\nBefore continuing on to some statistical ways of comparing reviews, it’s worth dwelling on our scale for a moment. In my experience, 5 star systems are the most common on the internet. But other common systems are 1-10 scales, up/down votes, and 0-100 scales. Ultimately, we will need to translate our 1-5 star scale to a probability between 0 and 1 in order to make statistical estimates easier.\nNote that a 1 star review is really a review of 0. You can’t give a score of 0 in most 5 star systems, so 1 is as low as you can go. So the first step to translating is to subtract 1 from the average review, so that we are now dealing with a 0-4 scale.\nThis is easy enough, although it does have some unintended side effects. 5/5 is still equivalent to 100%, but all of our other percentages have been pushed down: 4/5 has become 3/4 (75% instead of 80%), 3/5 has become 2/4 (50% instead of 60%), 2/5 has become 1/4 (25% instead of 40%), and 1/5 has become 0/4 (0% instead of 20%). I think this is how most people use a 5 star system anyway, with 3 stars as the midpoint and 2 and 4 midway between 3 stars and 1 and 5 respectively. But we have shifted the percentages down slightly.\nThis brings up an interesting point about translating reviews from their average and number of reviews or their distribution. On Google at least, you can usually get both metrics with a little digging. How do you translate from one to the other?\nTo go from distribution to average, you just add up the total number of stars awarded, and divide it by the total number of reviews. Here’s an example from Mama’s Too’s data:\n\n\n\n\n\n\n\n\n\n\n\n\n\nStar\nNumber of reviews\nNumber of stars\nTotal stars\nTotal reviews\nAverage review\n\n\n\n\n1\n258\n258\n11060\n2650\n4.17\n\n\n2\n120\n240\n11060\n2650\n4.17\n\n\n3\n191\n573\n11060\n2650\n4.17\n\n\n4\n416\n1664\n11060\n2650\n4.17\n\n\n5\n1665\n8325\n11060\n2650\n4.17\n\n\n\n\n\nIt isn’t possible to recover the exact distribution from the average and number of ratings. You might be able to approximate it, but consider the math we just did in the table above. A single 5-star review contributes the same number of stars as five 1-star reviews. So if our average was 3 stars with 2 reviews (6 total stars), there’s no way to tell if that represents two 3-star reviews or one 1-star and one 5-star. Those situations are equivalent.\nIf you’re interested, here is a little tool to experiment with different distributions and the resulting average review:\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(stringr)\n\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"n5\", \"5 stars\", 100,min = 0),\n    numericInput(\"n4\", \"4 stars\", 20,min = 0),\n    numericInput(\"n3\", \"3 stars\", 15,min = 0),\n    numericInput(\"n2\", \"2 stars\", 10,min = 0),\n    numericInput(\"n1\", \"1 stars\", 30,min = 0)\n  ),\n  card(textOutput(\"text\"),\n  plotOutput(\"plot\",width = \"auto\"))\n)\n\nserver &lt;- function(input, output, session) {\n  data &lt;- reactive({\n    data.frame(\n      stars = c(1,2,3,4,5),\n      number = c(input$n1,input$n2,input$n3,input$n4,input$n5)\n    ) |&gt;\n      mutate(number_of_stars = stars*number,\n             total_stars = sum(number_of_stars),\n             total_reviews = sum(number),\n             average_star = round(total_stars/total_reviews,2))\n    \n  })\n  \n  output$plot &lt;- renderPlot({\n    data() |&gt;\n      ggplot(aes(x = number, y = factor(stars))) + \n      geom_col(fill = \"goldenrod\") + \n      labs(x = \"Number of reviews\",\n           y = \"Star rating\") +\n      theme_bw()\n  }, res=140)\n  \n  output$text &lt;- renderText({\n    avg_review &lt;- data() |&gt;\n      pull(average_star) |&gt;\n      unique()\n    \n    num_reviews &lt;- \n      data() |&gt;\n      pull(total_reviews) |&gt;\n      unique()\n    \n    str_c(\"Average review: \", avg_review, \" with \" , num_reviews, \" reviews\")\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\nStatistical comparison\nThere is a great video by 3Blue1Brown on this topic, which I highly recommend. Some of these techniques are adapted from that video.\nThe first statistical technique for dealing with reviews comes from the world of coin flips and binomial distributions. Essentially, you treat the “true” underlying score as existing on a 0-1 scale. Then you treat each review as an independent draw from the binomial probability distribution. With the average and number of reviews, we can construct a confidence interval for the “true” score, and then compare confidence intervals between two restaurants with different numbers of reviews.\nIf you’re not used to statistical terminology, don’t be intimidated. The simple version of this is if we were to flip a coin 1000 times and got 600 heads and 400 tails, we are just trying to estimate the probability that the “true” probability for this coin is 60% heads and 40% tails.\nThe second technique (also outlined in the video) is called Laplace’s Rule of Succession, or simply Laplace’s technique. The idea is to take your current number of stars and reviews, and add 1 more negative review and 1 more positive review, and then calculate a new average. In the 5 star case, this is equivalent to adding 6 stars and 2 reviews to our totals.\nThe third technique is called Bayesian Averaging. The idea here is to start with some prior belief about what the average score is. This could be the average for the platform, or for the type of establishment (e.g. pizza restaurants on Google). We also take into account the average number of reviews for the same, so that we have a sense of whether our restaurant is above or below the average. Then we combine this knowledge with the number of stars and reviews for our given restaurant to get an updated estimate of the true average (called the “posterior”).\nActually Laplace’s technique, while an easy and convenient trick, is simply Bayesian average where the average prior review is 50% and the average number of reviews is 2.\nFinally, the most complicated technique is called empirical Bayes estimation (some more details at this blog post). Under the hood, this leverages special properties of the Beta distribution and Bayes theorem to improve our estimate beyond Bayesian averaging. It requires either having a lot of data, or estimating a prior distribution manually, which is what we’ll do in this case.\nBelow is a small app that allows you to test out all 4 of these different methods. You need the average rating and number of reviews for all methods. The two Bayesian methods also need some information on your “prior” assumptions. For Bayesian averaging, you need the prior average rating and number of reviews. For empirical Bayes estimation, you need to specify the alpha and beta values for the Beta distribution. For convenience, I have displayed the specified distribution and its mean and standard deviation to help with setting up the distribution.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(stringr)\n\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    numericInput(\"avg_stars\", \"Star Rating\", 4,\n                 min = 1, max = 5, step = 0.1),\n    numericInput(\"num_reviews\", \"Number of reviews\", 250,\n                 min = 0, step = 1),\n    numericInput(\"prior_stars\", \"Prior average rating (Bayesian average)\", 3.5,\n                 min = 1, max = 5, step = 0.1),\n    numericInput(\"prior_num\", \"Prior number of reviews (Bayesian average)\", 200),\n    numericInput(\"alpha\", \"Alpha (empirical Bayes)\", 3,\n                 step = 0.1,\n                 min = 0),\n    numericInput(\"beta\", \"Beta (empirical Bayes)\",1.5,\n                 step = 0.1,\n                 min = 0)\n  ),\n  navset_card_tab(\n    nav_panel(title = \"Comparison\",\n              plotOutput(\"comparison_plot\")),\n    nav_panel(title = \"Binomial CI\", \n              textOutput(\"binom_text\")),\n    nav_panel(title = \"Laplace\", \n              textOutput(\"laplace_text\")),\n    nav_panel(title = \"Bayesian Average\", \n              textOutput(\"bayes_avg_text\")),\n    nav_panel(title = \"Empirical Bayes\", \n              textOutput(\"beta_prior_text\"),\n              plotOutput(\"beta_dist\"), br(),\n              textOutput(\"beta_est\"))\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  binom_est &lt;- reactive({\n    p = (input$avg_stars - 1) / 4\n    high_ci = 1+4*qbinom(p = 0.975,size = input$num_reviews,prob=p)/input$num_reviews\n    low_ci = 1+4*qbinom(p = 0.025,size = input$num_reviews,prob=p)/input$num_reviews\n    \n    return(c(input$avg_stars,low_ci, high_ci))\n  })\n  \n  output$binom_text &lt;- renderText({\n        str_c(\"Mean: \", binom_est()[1],\", 95% CI: \",round(binom_est()[2],3),\"-\",round(binom_est()[3],3), \" stars\")\n  })\n  \n  laplace_est &lt;- reactive({\n      total_stars = (input$avg_stars - 1) * input$num_reviews\n      laplace_est = 1 + ((total_stars + 4) / (input$num_reviews + 2))\n      return(laplace_est)\n  })\n  \n  output$laplace_text &lt;- renderText({\n        str_c(\"Laplace estimate: \", round(laplace_est(),3), \" stars\")\n  })\n  \n  bayes_avg &lt;- reactive({\n    bayes_est &lt;- 1 + ((input$prior_num*(input$prior_stars-1))+ \n                        ((input$avg_stars-1) * input$num_reviews))/(input$prior_num + input$num_reviews)\n    bayes_est\n  })\n  \n  output$bayes_avg_text &lt;- renderText({\n    \n    str_c(\"Bayesian average: \", round(bayes_avg(),3), \" stars\")\n  })\n  \n  output$beta_prior_text &lt;- renderText({\n    alpha &lt;- input$alpha\n    beta &lt;- input$beta\n    \n    beta_mean &lt;- 1 + (4 * alpha / (alpha+beta))\n    \n    str_c(\"Beta prior mean: \", round(beta_mean,3), \" stars\")\n  })\n  \n  output$beta_dist &lt;- renderPlot({\n    x &lt;- seq(0, 1, length.out = 100)\n    y &lt;- dbeta(x, input$alpha, input$beta)\n    \n    rand_data = data.frame(points = 1 + (4*rbeta(1000, input$alpha, input$beta))) |&gt;\n      mutate(bin = case_when(points &lt; 1.5 ~ 1,\n                             points &gt;= 1.5 & points &lt; 2.5 ~ 2,\n                             points &gt;= 2.5 & points &lt; 3.5 ~ 3,\n                             points &gt;= 3.5 & points &lt; 4.5 ~ 4,\n                             points &gt;= 4.5~ 5)) |&gt;\n      summarize(.by = bin,\n                n =n())\n    \n    data.frame(x = x, y = y) |&gt;\n      mutate(x = 1 + (x*4)) |&gt;\n      ggplot() +\n      geom_line(aes(x = x, y = y)) +\n      # geom_col(data = rand_data,\n      #                aes(x = bin, y = n/1000),\n      #                alpha = 0.5) + \n      labs(title = paste(\"Beta Distribution (alpha =\", input$alpha, \", beta =\", input$beta, \")\"),\n           x = \"Star value\", y = \"Density\")\n  })\n  \n  beta_est &lt;- reactive({\n    adj_total_stars = (input$avg_stars - 1) * input$num_reviews\n\n    estimate = 1 + ((adj_total_stars + input$alpha) / (input$num_reviews + input$alpha + input$beta))\n    \n    return(estimate)\n  })\n  output$beta_est &lt;- renderText({\n    str_c(\"Empirical Bayes estimate: \", round(beta_est(), 3), \" stars\")\n  })\n  \n  output$comparison_plot &lt;- renderPlot({\n    data &lt;- data.frame(method = factor(c(\"Binomial CI\",\"Laplace\",\"Bayesian Average\",\"Empirical Bayes\"),\n                                         levels = c(\"Binomial CI\",\"Laplace\",\"Bayesian Average\",\"Empirical Bayes\")),\n               value = c(binom_est()[1], laplace_est(), bayes_avg(), beta_est()),\n               low_ci = c(binom_est()[2],NA,NA,NA),\n               high_ci = c(binom_est()[3],NA,NA,NA)\n               ) \n    data |&gt;\n      ggplot(aes(x = value, y = forcats::fct_rev(method))) +\n      geom_errorbar(aes(xmin = low_ci, xmax = high_ci),\n                    width = 0.2) +\n      geom_point(color = \"goldenrod\") +\n      theme_bw(base_size = 12) +\n      labs(x = \"Star Estimate\",y = \"Method\") + \n      xlim(1,5)\n  })\n}\n\nshinyApp(ui = ui, server = server)\nUltimately, these estimates have a lot of caveats because of the social factors discussed above. In my real life experience, word of mouth is usually the best indicator of a restaurant’s quality, and a place having thousands of reviews is an indicator that at the very least, it is popular and been around a long time. You’ll just have to visit to decide if it’s worth 5 stars.\n\n\n\nMama’s Too Pizza"
  }
]